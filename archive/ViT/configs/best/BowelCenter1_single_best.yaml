# ---------------------------------------------------------------------------- #
# data
# ---------------------------------------------------------------------------- #
data:
  train:
    img_dir: '../../Data/MR/imagesTr'
    ann_dir: '../../Data/MR/labelsTr'
  test:
    img_dir: '../../Data/MR/imagesTs'
    ann_dir: '../../Data/MR/labelsTs'
  sanity_check: False  # Sanity check means only 1 dataset sample to test overfitting
  augmentations:
    blur_prob: 0.85
    noise_prob: 0.25
    hflip_prob: 0.50
    rotate_max_deg: 45
    elastic_prob: 0.35 # See https://pytorch.org/vision/main/generated/torchvision.transforms.v2.ElasticTransform.html#torchvision.transforms.v2.ElasticTransform
    biasfield_prob: 0.70
    gamma_prob: 0.70

# ---------------------------------------------------------------------------- #
# Training options
# ---------------------------------------------------------------------------- #
training:
  batch_size: 1
  num_workers: 5
  epochs: 400
  DICE_weight: 1.0
  L1_weight: 0.0
  seed: 7
  accumulate_grad_batches: 1

model:
  name: "SwinUNETR"
  depths: [4, 4, 4, 4]
  num_heads: [3, 3, 6, 6]
  feature_size: 72
  norm_name: "instance"
  drop_rate: 0.30
  attn_drop_rate: 0.40
  dropout_path_rate: 0.55
  normalize: True
  use_checkpoint: True
  downsample: "mergingv2"
  use_v2: True
  dual_head: False

lr_scheduler:
  name: 'ReduceLROnPlateau'
  patience: 25

optimizer:
  name: 'Adam'  # SGD, Adam
  lr: 0.0003

logging:
  run_notes: ""
