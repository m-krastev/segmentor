# ---------------------------------------------------------------------------- #
# data
# ---------------------------------------------------------------------------- #
data:
  train:
    img_dir: '../../Data/MR/imagesTr'
    ann_dir: '../../Data/Segmentation/labelsTr'
  test:
    img_dir: '../../Data/MR/imagesTs'
    ann_dir: '../../Data/Segmentation/labelsTs'
  sanity_check: False  # Sanity check means only 1 dataset sample to test overfitting
  augmentations:
    blur_prob: 0
    noise_prob: 0
    hflip_prob: 0
    rotate_max_deg: 90
    elastic: # See https://pytorch.org/vision/main/generated/torchvision.transforms.v2.ElasticTransform.html#torchvision.transforms.v2.ElasticTransform
      prob: 0.0
      alpha: 50.0  # Magnitude of displacements
      sigma: 5.0  # Smoothness of displacements

# ---------------------------------------------------------------------------- #
# Training options
# ---------------------------------------------------------------------------- #
training:
  batch_size: 1
  num_workers: 10
  epochs: 400
  DICE_weight: 1.0
  L1_weight: 0.025
  seed: 7
  accumulate_grad_batches: 1

model:
  name: "SwinUNETR"
  depths: [3, 3, 3, 3]
  num_heads: [3, 6, 12, 24]
  feature_size: 48
  norm_name: "instance"
  drop_rate: 0.0
  attn_drop_rate: 0.0
  dropout_path_rate: 0.0
  normalize: True
  use_checkpoint: True
  downsample: "merging"
  use_v2: True
  dual_head: False

lr_scheduler:
  name: 'ReduceLROnPlateau'
  patience: 23

optimizer:
  name: 'Adam'  # SGD, Adam
  weight_decay: 0.0001  # Only for SGD
  momentum: 0.98  # Only for SGD
  lr: 0.0002388544691586894
  nesterov: True  # Only for SGD

logging:
  run_notes: ""
